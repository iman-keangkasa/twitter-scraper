import tweepy
from tweepy import OAuthHandler
import pandas as pd

print("Begin scraping.")

#Add your API access token in single quotations.

access_token = ''
access_token_secret = ''
consumer_key = ''
consumer_secret = ''

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

tweets = []

count = 1

#Twitter only pulls a sample of tweets from the last 7 days. 
#Enter one or multiple items seperated with or in search terms = '' - can be hashtags, keywords, handles, or key phrases of interest. 
#Manually add in the number of tweets you want to get back in items(). 
#Searches can further be filtered by added "-filter: retweets" or lang='en'.

search_term = '' 

for tweet in tweepy.Cursor(api.search, 
                           q=search_term, 
                           count=1000, 
                           tweet_mode='extended',
                           result_type='top',
                           since='YYYY-MM-DD').items():
    
    count += 1

    try: 
        data = [
            tweet.created_at, 
            tweet.id_str, 
            tweet.full_text.replace('&amp;','and').replace('‚Äô','\'').replace('‚Äú','\"'), 
            tweet.favorite_count, 
            tweet.retweet_count, 
            tweet.lang,
            tweet.user._json['screen_name'], 
            tweet.user._json['name'], 
            tweet.place,
            tweet.user.location, 
            tweet.source,
            tweet.in_reply_to_status_id_str, 
            tweet.in_reply_to_user_id_str,
            tweet.in_reply_to_screen_name,
            tweet.is_quote_status,
            tweet.user._json['created_at'], 
            tweet.entities['urls']
        ]
        data = tuple(data)
        tweets.append(data)
        
    except tweepy.TweepError as e:
        print(e.reason)
        continue

    except StopIteration:
        break

df = pd.DataFrame(tweets, columns = [
    'created at',
    'tweet id', 
    'tweet text', 
    'favorite count', 
    'retweet count', 
    'tweet language',
    'screenname', 
    'name',
    'tweet location',
    'user location', 
    'source',
    'if reply original tweet id',
    'if reply original user id',
    'if reply original user screenname',
    'quote tweet',
    'account creation date', 
    'entities'
])

#Add the path to the folder as well as the name of the output CSV file inside the single quotations

df.to_csv(path_or_buf = '', index=False) 

print("Finished scraping.")
